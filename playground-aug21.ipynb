{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycaret","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_columns', 999)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pycaret.regression import setup, compare_models, blend_models, finalize_model, predict_model, plot_model\n\nimport time\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/train.csv')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/test.csv')\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('/kaggle/input/tabular-playground-series-aug-2021/sample_submission.csv')\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.set_index('id') #setting ID as index\nX = train_df.drop(columns = ['loss']) # creating X dataframe\ny = train_df[['loss']] # creating y\n\ntest_df = test_df.set_index('id') #setting ID as index\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"# of records where no loss occurred\", len(train_df[train_df.loss == 0])/len(train_df)*100)\nprint(\"# of records where loss occurred\", len(train_df[train_df.loss != 0])/len(train_df)*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loss.value_counts(dropna=False)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**y variable**\n* 25% of the records incurred no losses, while 75% did\n* This might be something we could explicitly add to our model, as a binary variable in order to enhance the differentiation between loss & no-loss\n* Loss is also skewed to the left, we could address this distributions as well\n* our y variable is also an integer, so loss represents a specific number between 0 and 42","metadata":{}},{"cell_type":"code","source":"target_cols = X.columns\nfig, ax = plt.subplots(int(len(target_cols)/4), 4, figsize=(12, 48))\n\nrow1=0\nrow2=0\nrow3=0\nrow4=0\nfor var in enumerate(target_cols):\n    if var[0] < int(len(target_cols)/4):\n        sns.histplot(X[var[1]], ax = ax[row1, 0])\n        row1+=1\n    elif var[0] < int(len(target_cols)/4)*2:\n        sns.histplot(X[var[1]], ax = ax[row2, 1])\n        row2+=1\n    elif var[0] < int(len(target_cols)/4)*3:\n        sns.histplot(X[var[1]], ax = ax[row3, 2])\n        row3+=1\n    else:\n        sns.histplot(X[var[1]], ax = ax[row4, 3])\n        row4+=1\n\nfig.tight_layout()\nplt.show()\n","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Feature Distributions**\n* There are several features with distributions that are not normally distributed. \n* This includes skewed data as well as multiple-peak distributions.\n* Standardizing the data is not as helpful when distributions are not gaussian/normal.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a baseline model - linear regression\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression().fit(X_train, y_train)\nreg.score(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ny_pred_base = reg.predict(X_test)\ny_pred_base_rnd = y_pred_base.round() # rounding the findings to match loss integer format\nprint(y_pred_base_rnd)\nprint(mean_squared_error(y_test, y_pred_base_rnd, squared=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Baseline Model**\n* The R^2 is significantly low, at 0.01, meaning our model doesn't do a great job an capturing the relationship between our X variables and y\n* This is expected given the previous distribution analysis, since we're looking at non-linear relationships\n* RMSE - Root Mean Squared Error for our baseline model is 7.9 - this will be our baseline evaluation metric moving forward\n","metadata":{}},{"cell_type":"code","source":"# from scipy import stats\n\n# shapiro_scores = {}\n# for var in target_cols:\n#     score = stats.shapiro(X[var])\n#     shapiro_scores[var] = score[0]\n    \n# shapiro_df = pd.DataFrame.from_dict(shapiro_scores, orient='index').reset_index()\n# shapiro_df.columns = ['feature', 'shapiro_score']\n\n# shapiro_df['test_result'] = np.where(shapiro_df.shapiro_score <= 0.05, 'Normal', 'Non-Normal')\n\n# shapiro_df.test_result.value_counts(dropna=False) # none of the features are normally distributed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pycaret_model(train, target, test, n_select, fold, opt):\n  print('Setup Your Data....')\n  setup(data=train,\n              target=target,\n              numeric_imputation = 'mean',\n              silent= True)\n  \n  print('Comparing Models....')\n  best = compare_models(sort=opt, n_select=n_select, fold = fold, exclude = ['xgboost'])\n\n  print('Here is Best Model Feature Importances!')\n  plot_model(estimator = best[0], plot = 'feature')\n  time.sleep(5)\n  \n  print('Blending Models....')\n  blended = blend_models(estimator_list= best, fold=fold, optimize=opt)\n  pred_holdout = predict_model(blended)\n    \n  print('Finallizing Models....')\n  final_model = finalize_model(blended)\n  print('Done...!!!')\n\n  pred_esb = predict_model(final_model, test)\n  re = pred_esb['Label']\n\n  return re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['loss'] = np.exp(pycaret_model(train_df, 'loss', test_df, 5, 3, 'RMSLE'))-1","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}